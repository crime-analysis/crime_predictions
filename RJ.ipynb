{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read from crimes.csv\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install dask[dataframe]\n",
    "#!pip install pandas --upgrade\n",
    "# We have to do this as dask is bad at guessing the types of objects for some reason\n",
    "# Also, if you are having trouble with running the dataframe and continuously get \n",
    "# Fatal Python error: GC object already tracked, try to update pandas\n",
    "data_types = {\n",
    "    'ID':  np.int64,\n",
    "    'Case Number':  object,\n",
    "    'Date': object,\n",
    "    'Block': object,\n",
    "    'IUCR': object,\n",
    "    'Primary Type': object,\n",
    "    'Description':  object,\n",
    "    'Location Description': object,\n",
    "    'Arrest':  bool,\n",
    "    'Domestic': bool,\n",
    "    'Beat': np.int64,\n",
    "    'District': np.float64,\n",
    "    'Ward': np.float64,\n",
    "    'Community Area': np.float64,\n",
    "    'FBI Code': object,\n",
    "    'X Coordinate': np.float64,\n",
    "    'Y Coordinate': np.float64,\n",
    "    'Year': np.int64,\n",
    "    'Updated On': object,\n",
    "    'Latitude': np.float64,\n",
    "    'Longitude': np.float64,\n",
    "    'Location': object\n",
    "}\n",
    "df = pd.read_csv('crimes.csv')\n",
    "print(\"finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert date and time to different formats in a new DataFrame and store in .h5 file\n",
    "\n",
    "import datetime\n",
    "import locale\n",
    "\n",
    "store = pd.HDFStore('store.h5')\n",
    "\n",
    "\n",
    "data_subset = pd.DataFrame(df.subset(20000).Date)\n",
    "\n",
    "# add columns\n",
    "data_subset.insert(0, 'Hour', 0)\n",
    "data_subset.insert(0, 'Day', 0)\n",
    "data_subset.insert(0, 'Month', 0)\n",
    "data_subset.insert(0, 'Year', 0)\n",
    "\n",
    "# FORMAT : 06/25/2012 03:00:00 PM\n",
    "\n",
    "# convert string date time to 24 hour (just hour)\n",
    "# output as string\n",
    "def to24Hour(x):\n",
    "    hour = x[11:13]\n",
    "    am = x[-2:] == 'AM'\n",
    "    if(am):\n",
    "        if(hour == '12'):\n",
    "            hour = '00'\n",
    "        else:\n",
    "            return hour\n",
    "    else:\n",
    "        if(hour != '12'):\n",
    "            hour = str(int(hour) + 12)\n",
    "\n",
    "    return hour\n",
    "\n",
    "# convert string to datetime object with only date\n",
    "def toDate(x):\n",
    "    month = x[0:2]\n",
    "    date = x[3:5]\n",
    "    year = x[6:10]\n",
    "    return datetime.datetime(int(year), int(month), int(date))\n",
    "\n",
    "def toMonth(x):\n",
    "    return x[0:2]\n",
    "\n",
    "def toYear(x):\n",
    "    return x[6:10]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# convert date\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "#datetime.datetime.strptime('06/25/2012 03:00:00 PM', '%x %X %p').strftime('%A')\n",
    "#https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior\n",
    "data_subset['Hour'] = data_subset['Date'].apply(to24Hour)\n",
    "data_subset['Day'] = data_subset['Date'].apply(lambda x: toDate(x).strftime('%w'))\n",
    "data_subset['Month'] = data_subset['Date'].apply(toMonth)\n",
    "data_subset['Year'] = data_subset['Date'].apply(toYear)\n",
    "\n",
    "# save to HDF5\n",
    "store['data_subset'] = data_subset\n",
    "#retrieve with varName = store['data_subset']\n",
    "\n",
    "store.close()\n",
    "\n",
    "data_subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "# start from here if reading from .h5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "store = pd.HDFStore('store.h5')\n",
    "\n",
    "data_subset = store['data_subset']\n",
    "\n",
    "print(\"finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of crimes vs hour of day\n",
    "\n",
    "hourCounts = data_subset.Hour.value_counts().sort_index()\n",
    "\n",
    "X = np.arange(len(hourCounts))\n",
    "\n",
    "plt.bar(X, hourCounts.values)\n",
    "\n",
    "plt.xticks(X, hourCounts.axes[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of crimes vs day of week\n",
    "\n",
    "dayCounts = data_subset.Day.value_counts().sort_index()\n",
    "\n",
    "X = np.arange(len(dayCounts))\n",
    "\n",
    "plt.bar(X, dayCounts.values, align='center')\n",
    "\n",
    "plt.xticks(X, ['S', 'M', 'T', 'W', 'Th', 'F', 'Sa'])\n",
    "\n",
    "# axes = plt.gca()\n",
    "# axes.set_ylim([800000,1000000])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of crimes vs month for years 2001-15 (excludes 16)\n",
    "\n",
    "# divide by number of days in each month\n",
    "def monthNormalize(monthCounts):\n",
    "    i = 1\n",
    "    for key in monthCounts:\n",
    "        if(i in [1, 3, 5, 7, 8, 10, 12]):\n",
    "            monthCounts[i-1] /= 31\n",
    "        elif (i == 2):\n",
    "            monthCounts[i-1] /= 28.25 #2001-16 has 4 leap febs and 12 non-leap febs\n",
    "        else :\n",
    "            monthCounts[i-1] /= 30 \n",
    "        i += 1\n",
    "            \n",
    "    return monthCounts\n",
    "\n",
    "# exclude 2016    \n",
    "monthCounts = data_subset.where(data_new['Year'] != '2016').Month.value_counts().sort_index()\n",
    "#monthCounts = data_subset.Month.value_counts().sort_index()\n",
    "\n",
    "monthCounts = monthNormalize(monthCounts)\n",
    "\n",
    "X = np.arange(len(monthCounts))\n",
    "\n",
    "plt.bar(X, monthCounts.values, align='center')\n",
    "\n",
    "plt.xticks(X,  ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([14000,18000])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of crimes vs year\n",
    "\n",
    "yearCounts = data_subset.Year.value_counts().sort_index()\n",
    "\n",
    "X = np.arange(len(yearCounts))\n",
    "\n",
    "plt.bar(X, yearCounts.values, align='center')\n",
    "\n",
    "plt.xticks(X, yearCounts.axes[0].map(lambda x : x[-2:]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-processing for prediction\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "for i in range(2001, 2016):\n",
    "    year = str(i)\n",
    "    ser = pd.Series(data_subset.where(data_new['Year'] == year).Month.value_counts(), name=year)\n",
    "    rows_list.append(ser)\n",
    "\n",
    "counts_frame = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict for 2016 based on first three months\n",
    "\n",
    "# get 2016 series\n",
    "i = 2016\n",
    "year = str(i)\n",
    "ser = pd.Series(data_subset.where(data_new['Year'] == year).Month.value_counts(), name=year)\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# predict all other months from first Jan, Feb and Mar\n",
    "indep_vars = ['01', '02', '03']\n",
    "dep_vars = ['04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "indep_data = counts_frame[indep_vars]\n",
    "dep_data = counts_frame[dep_vars]\n",
    "\n",
    "# train on 2001-2015, predict on 2016\n",
    "indep_train = indep_data\n",
    "dep_train = dep_data\n",
    "indep_test = pd.DataFrame(ser).T.drop('04', 1)\n",
    "\n",
    "# fit\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(indep_train, dep_train)\n",
    "\n",
    "# predict\n",
    "regr_predict = regr.predict(indep_test)\n",
    "\n",
    "predicted_year_crime_2016 = np.sum(regr_predict)\n",
    "\n",
    "plt.bar(range(1, 4), indep_test.as_matrix()[0], align = 'center')\n",
    "plt.bar(range(4, 13), regr_predict[0], align = 'center', color = 'red')\n",
    "\n",
    "plt.xticks(range(1, 13),  ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 65.90%\n"
     ]
    }
   ],
   "source": [
    "# train and test the normal way to find R2\n",
    "\n",
    "indep_vars = ['01', '02', '03']\n",
    "dep_vars = ['04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "indep_data = counts_frame[indep_vars]\n",
    "dep_data = counts_frame[dep_vars]\n",
    "indep_train, indep_test, dep_train, dep_test = train_test_split(indep_data, dep_data, test_size=0.01, random_state=42)\n",
    "\n",
    "# train\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(indep_train, dep_train)\n",
    "\n",
    "# predict\n",
    "regr_predict = regr.predict(indep_test)\n",
    "\n",
    "# find numerator\n",
    "numerator = np.mean(np.square(dep_test.as_matrix() - regr_predict))\n",
    "\n",
    "# find denominator\n",
    "a = []\n",
    "for i in range(0, len(dep_test)):\n",
    "    a.append(np.mean(dep_train, axis = 0))\n",
    "    \n",
    "denominator = np.mean(np.square(dep_test.as_matrix() - a))\n",
    "\n",
    "# calculate R2\n",
    "R2 = 1 - (numerator / denominator)\n",
    "\n",
    "print(\"R2 = %.2f%%\" % (R2*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of crimes vs year with predicted 2016\n",
    "\n",
    "yearCounts = data_subset.Year.value_counts().sort_index()\n",
    "\n",
    "plt.bar(np.array(len(yearCounts) - 1), np.array(yearCounts['2016'] + predicted_year_crime_2016), align='center', color='red')\n",
    "#print(yearCounts['2016'] + predicted_year_crime_2016)\n",
    "\n",
    "X = np.arange(len(yearCounts))\n",
    "\n",
    "plt.bar(X, yearCounts.values, align='center', tick_label=yearCounts.values)\n",
    "\n",
    "plt.xticks(X, yearCounts.axes[0].map(lambda x : x[-2:]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year Month Day Hour                    Date\n",
      "979104   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979158   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979174   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979201   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979205   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979222   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979245   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979326   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979353   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979366   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979398   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979415   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979487   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979541   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979585   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979627   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "979853   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "980081   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "980928   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "981104   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "982023   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "982085   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "985481   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "986765   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "988293   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "989759   2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "1051062  2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "1060002  2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "1187994  2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "2474259  2001    01   1   01  01/01/2001 01:00:00 AM\n",
      "...       ...   ...  ..  ...                     ...\n",
      "919081   2016    04   2   12  04/12/2016 12:20:00 PM\n",
      "901596   2016    04   2   00  04/12/2016 12:22:00 AM\n",
      "906163   2016    04   2   12  04/12/2016 12:25:00 PM\n",
      "907279   2016    04   2   12  04/12/2016 12:27:00 PM\n",
      "901171   2016    04   2   00  04/12/2016 12:28:00 AM\n",
      "902882   2016    04   2   00  04/12/2016 12:30:00 AM\n",
      "920152   2016    04   2   00  04/12/2016 12:30:00 AM\n",
      "906650   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "907447   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "908545   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "909288   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "909321   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "912190   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "919567   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "919887   2016    04   2   12  04/12/2016 12:30:00 PM\n",
      "904145   2016    04   2   00  04/12/2016 12:38:00 AM\n",
      "903038   2016    04   2   00  04/12/2016 12:40:00 AM\n",
      "901615   2016    04   2   00  04/12/2016 12:45:00 AM\n",
      "918836   2016    04   2   00  04/12/2016 12:45:00 AM\n",
      "919596   2016    04   2   00  04/12/2016 12:45:00 AM\n",
      "907240   2016    04   2   12  04/12/2016 12:45:00 PM\n",
      "907373   2016    04   2   12  04/12/2016 12:45:00 PM\n",
      "906310   2016    04   2   12  04/12/2016 12:46:00 PM\n",
      "901429   2016    04   2   00  04/12/2016 12:50:00 AM\n",
      "903152   2016    04   2   00  04/12/2016 12:50:00 AM\n",
      "908145   2016    04   2   12  04/12/2016 12:50:00 PM\n",
      "917669   2016    04   2   12  04/12/2016 12:50:00 PM\n",
      "908820   2016    04   2   12  04/12/2016 12:51:00 PM\n",
      "901671   2016    04   2   00  04/12/2016 12:52:00 AM\n",
      "908216   2016    04   2   12  04/12/2016 12:59:00 PM\n",
      "\n",
      "[6040759 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(data_subset.sort_values(['Year', 'Month', 'Date']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
